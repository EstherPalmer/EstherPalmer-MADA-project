---
title: "Example Manuscript Template for a Data Analysis Project"
author: ""
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../../assets/dataanalysis-references.bib
csl: ../../assets/american-journal-of-epidemiology.csl
---

The structure below is one possible setup for a manuscript stemming from a data analysis project. It loosely follows the structure of a standard scientific manuscript. Adjust as needed. You don't need to have exactly these sections, but the content covering those sections should be addressed.

This uses [MS Word as output format](https://quarto.org/docs/output-formats/ms-word.html). See [the Quarto documentation](https://quarto.org/) for instructions on how to use other formats.


```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
```


**Authors**  

* Esther Palmer$^{1}$ (ORCID: 0000-0000-1234-5678) 
* Dawson Deal$^{1}$
* Kaya Palukaitis$^{1}$
* Elisabeth Drake$^{2}$ 
* Erin Lipp$^{2}$ 
* Nikki Shariat$^{1, \land}$ 

**Author affiliations**  

1. Departments of Microbiology and Population Health, University of Georgia, Athens, GA, USA.
2. Environmental something? will fix later, University of Georgia, Athens, GA, USA.


$*$ These authors contributed equally to this work.

$\land$ Corresponding author: some@email.com

$\dagger$ Disclaimer: The opinions expressed in this article are the
author's own and don't reflect their employer.

I (Esther) will be the only one doing modeling on this project, however I do want to acknowledge the undergrads who did a majority of the actual data collection (Dawson and Kaya) because they are fantastic, as well as our collaborators in other labs who helped with some of the other data generation.

{{< pagebreak >}}



# Summary/Abstract
_Write a summary of your project._

_It is recommended to use a structured abstract with Background/Methods/Results/Discussion sections._

{{< pagebreak >}}


# Introduction 

## General Background Information
_Provide enough background on your topic that others can understand the why and how of your analysis_
_Salmonella_ is an enteric bacteria responsible for over 1 million illnesses/year in the US. Nearly half of those ilnesses come from fresh produce (cite IFSAC report which hasn't been updated for most recent year due to stupid politics). One of the main ways produce can become contaminated with _Salmonella_ is due to the use of contaminated irrigation water. As such it is important to study the dynamics of _Salmonella_ populations in water.
_Salmonella_ is an incredibly diverse organism with over 2600 serovars (cite kaufmann white scheme). These different serovars pose different risks to human and agricultural health. (insert statistic about how like only 100 of those 2600 serovars really cause human illness). As such it is important to study _Salmonella_ on a serovar level.

It has been well established that _Salmonella_ can be found in surface water such as creeks/rivers/ponds/lakes (Insert literally all the refs), and that such samples typically contain high diversity of Serovars (Deavon 2021, Smith/Siceloff 2025, My CC paper if I can ever get it out the door). However, much is unknown about the daily population dynamics of these serovars over time.

The purpose of this study is to figure out what _Salmonella_ does on a daily basis. Are populations stable? Do we see lots of changes? How long does a given serovar stay in the creek? The purpose of this project for this class is to look at how environmental and weather variables affect _Salmonella_ serovars in the creek.

## Description of data and data source
_Describe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section._
We went sampling for _Salmonella_ at an urban creek every weekday for 6 months (179 days from start, ~150 days total not including weekends), and then once a week for another 9 months or so. I will probably focus my analysis on only that 6 month period. Prevalence of _Salmonella_ was ~96% (will double check # later). 
We also collected environmental data (pH turbidity conductivity flow depth etc.) as well as weather data from the nearest UGA weather station (insert link).
Overall I believe that there are 22 environmental variables I have data for (not including date). Many of them will be correlated and some can be dropped. For example, salinity while collected has only ever been not 0 once in all my years of collecting it.
I have not cleaned or really ever checked the weather data, however any missing data can be obtained by emailing the weather people because they keep records of all this.
CRISPR-SeroSeq (CSS) was performed on the samples to get serovar level population data. CSS data was collected for both RV and TT samples, then reads were normalized using DeSeq2 and then averaged across the two sample types to create one entry per collection day. There are some days where CSS didn't work.
I also have whole genome sequencing data for some samples/isolates, but that may be outside the scope of this project for this class.

## Questions/Hypotheses to be addressed
_State the research questions you plan to answer with this analysis._

Given that the prevalence of _Salmonella_ is so high I don't think it would be productive to attempt to model for _Salmonella_ prevalence. Also previous studies attempting to model for this using environmental/weather data all come up with contradictory results.
I can instead attempt to see if environmental/weather data affects _Salmonlla_ complexity (complexity = # serovars/sample) which is not something other papers have looked at/been able to look at.
I also would like to see if environmental/weather variables affect the prevalence of specific _Salmonella_ serovars. (For example, are we more likely to find Muenchen on hot days, or Anatum after rain). Other papers have not been able to consider serovar level data when looking at effects of weather/environmental data. I have preliminary data from my other projects that do suggest that things like rain might affect some serovars more than others.
One thing that may make things more complicated or may help is that I do have all the values from every day, so I can ask things like whether the weather the day before or day of sampling is more important. So maybe rain the day before sampling has more of an impact than rain the day of sampling.

To cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the BibTeX file specified in the YAML header above and have the right BibTeX key. Then you can include like this:

Examples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a].



{{< pagebreak >}}


# Methods 

_Describe your methods. That should describe the data, the cleaning processes, and the analysis approaches. You might want to provide a shorter description here and all the details in the supplement._


## Schematic of workflow

Sometimes you might want to show a schematic diagram/figure that was not created with code (if you can do it with code, do it). @fig-schematic is an example of some - completely random/unrelated - schematic that was generated with BioRender.
We store those figures in the `assets` folder.

```{r}
#| label: fig-schematic
#| fig-cap: "A figure that is manually generated and shows some overview/schematic. This has nothing to do with the data, it's just a random one from one of our projects I found and placed here."
#| echo: FALSE
knitr::include_graphics(here("assets","antigen-recognition.png"))
```




## Data acquisition
_As applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next._


## Data import and cleaning
_Write code that reads in the file and cleans it so it's ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along._

```{r}
#path to data
enviro_data_location <- here::here("data","raw-data","Environmental_Data_Final.xlsx")
CSS_data_location <- here::here("data", "raw-data", "Daily_Sampling_Normalized_CSS_6mo.xlsx")
#load data.
#there are 2 files, one containing the environmental/weather data, and one containing CSS data
enviro_rawdata <- readxl::read_excel(enviro_data_location, sheet = "Sheet2")
#I am going to use the dataset that excludes weekends for this preliminary look, Sheet1 contains the data that has weekends
CSS_rawdata <- readxl::read_excel(CSS_data_location)
#This will read in the CSS data
```
This code chunk loads my raw data. I have two files, one with completed CSS analysis, and another with environmental and weather variables. The environmental and weather variable excel sheet has 2 sheets, on sheet1 there is all the data including the weather data for the weekends. On sheet2 the weekend data was removed and only data for the day of sampling was left.

```{r}
dplyr::glimpse(enviro_rawdata)
#looking at the raw environmental data
summary(enviro_rawdata)
```

This provides a look at all the environmental data. I can see several variables have been listed as characters when they need to be numeric, and there are several NAs so I will have some cleaning to do in the future. I also don't trust DO I think the instrument was acting up so I kinda want to drop the whole variable. Day is also being treated like a numeric variable rather than an ordinal (I think ordinal? it has order) variable. Although maybe it is quantitative since you can do things like addition to it?

## Statistical analysis
_Explain anything related to your statistical analyses._


{{< pagebreak >}}


# Results

## Exploratory/Descriptive analysis

_Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project._


@tbl-summarytable shows a summary of the data.

Note the loading of the data providing a **relative** path using the `../../` notation. (Two dots means a folder up). You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path. You can also use the `here` R package to create paths. See examples of that below. I generally recommend the `here` package.

```{r}
#| label: tbl-summarytable
#| tbl-cap: "Data summary table."
#| echo: FALSE
resulttable <- readRDS("../../results/tables/summarytable.rds")
knitr::kable(resulttable)
```



## Basic statistical analysis

_To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p<0.05 means statistical significance" interpretation is not valid._


@fig-result shows a scatterplot figure produced by one of the R scripts.

```{r}
#| label: fig-result
#| fig-cap: "Height and weight stratified by gender."
#| echo: FALSE
knitr::include_graphics(here("results","figures","height-weight-stratified.png"))
```


## Full analysis

_Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here._

Example @tbl-resulttable2 shows a summary of a linear model fit.

```{r}
#| label: tbl-resulttable2
#| tbl-cap: "Linear model fit table."
#| echo: FALSE
resulttable2 <- readRDS(here("results","tables","resulttable2.rds"))
knitr::kable(resulttable2)
```


{{< pagebreak >}}


# Discussion

## Summary and Interpretation
_Summarize what you did, what you found and what it means._

## Strengths and Limitations
_Discuss what you perceive as strengths and limitations of your analysis._

## Conclusions
_What are the main take-home messages?_

_Include citations in your Qmd file using BibTeX, the list of references will automatically be placed at the end_

This paper [@leek2015] discusses types of analyses. 

These papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template. 

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal [are available](https://www.zotero.org/styles). You also specify the location of your BibTeX reference file in the YAML. You can call your reference file anything you like.


{{< pagebreak >}}

# References



